{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VisualizeConvFeatures.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tiago1Ribeiro/VisualizeConvFeatures/blob/master/VisualizeConvFeatures.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "EC27OXrsbS80",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### **Código sugerido no artigo** \"[How to visualize convolutional features in 40 lines of code](https://towardsdatascience.com/how-to-visualize-convolutional-features-in-40-lines-of-code-70b7d87b0030)\""
      ]
    },
    {
      "metadata": {
        "id": "w9c7Ql1OXnzw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Instalacao de bibliotecas"
      ]
    },
    {
      "metadata": {
        "id": "b3STij4XXmlB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install fastai==0.7.0      # versao que funciona com esta estrutura nas bibliotecas \"fastai.conv_learner\"\n",
        "!pip install opencv-python\n",
        "!pip install torchtext==0.2.3   # mais 'ceteris paribus' para não dar erro..."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "x36btLmdW1YI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Importação de bibliotecas"
      ]
    },
    {
      "metadata": {
        "id": "qloefQ7bWO5K",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "from fastai.conv_learner import *             \n",
        "from cv2 import resize            # cv2\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XKjYnbxRZ0Jj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Grava ** features ** => dado de entrada; em camadas posteriores escondidas: filtros ou caracteristicas de um filtro"
      ]
    },
    {
      "metadata": {
        "id": "BCEw9W1_ZzY0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class SaveFeatures():\n",
        "    def __init__(self, module):\n",
        "        self.hook = module.register_forward_hook(self.hook_fn)\n",
        "    def hook_fn(self, module, input, output): # foward hook\n",
        "        self.features = torch.tensor(output,requires_grad=True).cuda()\n",
        "    def close(self):\n",
        "        self.hook.remove()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "z2NmYJu8aeEz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Onde se dá a magia...\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "1oobJCw-aePd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class FilterVisualizer():\n",
        "    def __init__(self, size=56,upscaling_steps=12, upscaling_factor=1.2):\n",
        "        self.size, self.upscaling_steps, self.upscaling_factor = size, upscaling_steps, upscaling_factor\n",
        "        self.model = vgg16(pre=True).cuda().eval()\n",
        "        set_trainable(self.model, False)\n",
        "\n",
        "    def visualize(self, layer, filter, lr=0.1, opt_steps=20, blur=None):\n",
        "        sz = self.size\n",
        "        img = np.uint8(np.random.uniform(150, 180, (sz, sz, 3)))/255    # generate random image\n",
        "        activations = SaveFeatures(list(self.model.children())[layer])  # register hook\n",
        "\n",
        "        for _ in range(self.upscaling_steps):   # scale the image up upscaling_steps times\n",
        "            train_tfms, val_tfms = tfms_from_model(vgg16, sz)\n",
        "            img_var = V(val_tfms(img)[None], requires_grad=True)  # convert image to Variable that requires grad\n",
        "            optimizer = torch.optim.Adam([img_var], lr=lr, weight_decay=1e-6)\n",
        "            for n in range(opt_steps):  # optimize pixel values for opt_steps times\n",
        "                optimizer.zero_grad()\n",
        "                self.model(img_var)\n",
        "                loss = -activations.features[0, filter].mean()\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "            img = val_tfms.denorm(img_var.data.cpu().numpy()[0].transpose(1,2,0))\n",
        "            self.output = img\n",
        "            sz = int(self.upscaling_factor * sz)  # calculate new image size\n",
        "            img = cv2.resize(img, (sz, sz), interpolation = cv2.INTER_CUBIC)  # scale image up\n",
        "            if blur is not None: img = cv2.blur(img,(blur,blur))  # blur image to reduce high frequency patterns\n",
        "        self.save(layer, filter)\n",
        "        activations.close()\n",
        "        \n",
        "    def save(self, layer, filter):\n",
        "        plt.imsave(\"layer_\"+str(layer)+\"_filter_\"+str(filter)+\".jpg\", np.clip(self.output, 0, 1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8U9ganSicUpM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Pick a layer and filter"
      ]
    },
    {
      "metadata": {
        "id": "UdNeHKbvcUxp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "layer = 40\n",
        "filter = 265\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Yr3UUhgzlVsh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "FV = FilterVisualizer(size=56, upscaling_steps=12, upscaling_factor=1.2)\n",
        "FV.visualize(layer, filter, blur=5)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tU2rgelulZgn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "img = PIL.Image.open(\"layer_\"+str(layer)+\"_filter_\"+str(filter)+\".jpg\")\n",
        "plt.figure(figsize=(7,7))\n",
        "plt.imshow(img)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}